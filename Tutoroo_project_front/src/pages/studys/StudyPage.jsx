/** @jsxImportSource @emotion/react */
import { useState, useEffect, useRef } from "react";
import Header from "../../components/layouts/Header";
import SessionStatus from "../../components/studys/SessionStatus"; 
import useStudyStore from "../../stores/useStudyStore";
import { studyApi } from "../../apis/studys/studysApi"; 
import * as s from "./styles";
import tigerImg from "../../assets/images/mascots/logo_tiger.png";
import turtleImg from "../../assets/images/mascots/logo_turtle.png";
import rabbitImg from "../../assets/images/mascots/logo_rabbit.png";
import kangarooImg from "../../assets/images/mascots/logo_icon.png";
import dragonImg from "../../assets/images/mascots/logo_dragon.png";

const TUTOR_IMAGES = {
  tiger: tigerImg,
  turtle: turtleImg,
  rabbit: rabbitImg,
  kangaroo: kangarooImg,
  eastern_dragon: dragonImg,
  dragon: dragonImg 
};

// [New] API ê¸°ë³¸ URL ì„¤ì • (í™˜ê²½ë³€ìˆ˜ ì—†ìœ¼ë©´ ë¡œì»¬í˜¸ìŠ¤íŠ¸ ê¸°ë³¸ê°’)
const API_BASE_URL = import.meta.env.VITE_API_BASE_URL || "http://localhost:8080";

function StudyPage() {
  const { 
    messages, 
    sendMessage, 
    isChatLoading, 
    selectedTutorId,
    isSpeakerOn,
    toggleSpeaker,
    currentMode,
    planId,
    studyDay,
    initializeStudySession 
  } = useStudyStore();

  const [inputText, setInputText] = useState("");
  const [isRecording, setIsRecording] = useState(false); 
  const scrollRef = useRef(null);
  const audioRef = useRef(new Audio());
  const mediaRecorderRef = useRef(null); 
  const audioChunksRef = useRef([]);

  // ê¸°ë³¸ ì´ë¯¸ì§€ë¥¼ ìº¥ê±°ë£¨ë¡œ ë³€ê²½ (ì„ íƒëœ IDê°€ ì—†ì„ ê²½ìš° ëŒ€ë¹„)
  const currentTutorImage = TUTOR_IMAGES[selectedTutorId] || kangarooImg;

  useEffect(() => {
    // startClassSessionì„ í†µí•´ ì´ë¯¸ ë©”ì‹œì§€ê°€ ë¡œë“œëœ ìƒíƒœë¼ë©´ ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€ ë¡œì§ì´ Store ë‚´ë¶€ì— ìˆìŒ
    initializeStudySession();
  }, []); 

  // ìŠ¤í¬ë¡¤ ìë™ ì´ë™
  useEffect(() => {
    if (scrollRef.current) scrollRef.current.scrollTop = scrollRef.current.scrollHeight;
  }, [messages, isChatLoading, isRecording]);

  // [ìˆ˜ì •] TTS ìë™ ì¬ìƒ ë¡œì§ (ê²½ë¡œ ë¬¸ì œ í•´ê²°)
  useEffect(() => {
    if (messages.length > 0 && isSpeakerOn) {
      const lastMsg = messages[messages.length - 1];
      
      // AI ë©”ì‹œì§€ì´ê³  ì˜¤ë””ì˜¤ URLì´ ìˆëŠ” ê²½ìš°
      if (lastMsg.type === 'AI' && lastMsg.audioUrl) {
        audioRef.current.pause();
        
        // [í•µì‹¬] URLì´ httpë¡œ ì‹œì‘í•˜ì§€ ì•Šìœ¼ë©´(ìƒëŒ€ê²½ë¡œë©´) ë°±ì—”ë“œ ì£¼ì†Œë¥¼ ë¶™ì—¬ì¤Œ
        const fullUrl = lastMsg.audioUrl.startsWith("http") 
          ? lastMsg.audioUrl 
          : `${API_BASE_URL}${lastMsg.audioUrl}`;

        audioRef.current.src = fullUrl;
        
        // ë¸Œë¼ìš°ì € ì •ì±…ìƒ ì‚¬ìš©ì ì¸í„°ë™ì…˜ ì—†ì´ëŠ” ìë™ ì¬ìƒì´ ë§‰í ìˆ˜ ìˆìŒ (ì˜ˆì™¸ì²˜ë¦¬)
        audioRef.current.play().catch(e => {
            console.log("Audio play blocked (user interaction needed):", e);
        });
      }
    } else {
        // ìŠ¤í”¼ì»¤ê°€ êº¼ì ¸ìˆìœ¼ë©´ ì¬ìƒ ì¤‘ë‹¨
        audioRef.current.pause(); 
    }
  }, [messages, isSpeakerOn]);

  const handleSend = () => {
    if (!inputText.trim() || isChatLoading) return;
    sendMessage(inputText);
    setInputText("");
  };

  const handleKeyDown = (e) => {
    if (e.key === "Enter" && !e.nativeEvent.isComposing) handleSend();
  };

  // [ìˆ˜ì •] STT ë…¹ìŒ ì‹œì‘ (webm í¬ë§· ì ìš©)
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      
      // ë¸Œë¼ìš°ì € í˜¸í™˜ì„±ì„ ìœ„í•´ webm ì„ í˜¸ (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ê¸°ë³¸ê°’ ì‚¬ìš©)
      const mimeType = MediaRecorder.isTypeSupported("audio/webm") ? "audio/webm" : "";
      mediaRecorderRef.current = new MediaRecorder(stream, { mimeType });
      
      audioChunksRef.current = [];
      
      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0) audioChunksRef.current.push(event.data);
      };
      
      mediaRecorderRef.current.onstop = async () => {
        // [í•µì‹¬] mp3 -> webmìœ¼ë¡œ ë³€ê²½ (OpenAI Whisper í˜¸í™˜ì„± ë° ë¸Œë¼ìš°ì € ì§€ì› ìµœì í™”)
        const audioBlob = new Blob(audioChunksRef.current, { type: "audio/webm" });
        setIsRecording(false);
        try {
          const text = await studyApi.uploadAudio(audioBlob);
          if (text) setInputText(text); 
        } catch (e) {
            console.error("STT Error", e);
            alert("ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
        }
        // ë…¹ìŒ ì¢…ë£Œ í›„ ìŠ¤íŠ¸ë¦¼ íŠ¸ë™ ì •ì§€ (ë§ˆì´í¬ ì•„ì´ì½˜ êº¼ì§ ì²˜ë¦¬)
        stream.getTracks().forEach(track => track.stop());
      };
      
      mediaRecorderRef.current.start();
      setIsRecording(true);
    } catch (e) {
      console.error("Mic access error:", e);
      alert("ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.");
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) mediaRecorderRef.current.stop();
  };

  const handleDownloadPdf = async () => {
    try {
        const blob = await studyApi.downloadReviewPdf(planId, studyDay);
        const url = window.URL.createObjectURL(new Blob([blob]));
        const link = document.createElement('a');
        link.href = url;
        link.setAttribute('download', `Study_Review_Day${studyDay}.pdf`);
        document.body.appendChild(link);
        link.click();
        link.remove();
    } catch (e) {
        alert("ë³µìŠµ ìë£Œë¥¼ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
    }
  };

  return (
    <>
      <Header />
      <div css={s.pageContainer}>
        <main css={s.chatArea} ref={scrollRef}>
          {messages.length === 0 ? (
            <div css={s.placeholder}>
              <p>ë‚´ í•™ìŠµ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...</p>
            </div>
          ) : (
            messages.map((msg, index) => {
              const isUser = msg.type === "USER";
              return (
                <div key={index} css={s.messageRow(isUser)}>
                  {!isUser && (
                    <div css={s.aiProfileIcon}>
                      <img src={currentTutorImage} alt="tutor" />
                    </div>
                  )} 
                  <div css={s.bubble(isUser)}>
                    {msg.content}
                  </div>
                </div>
              );
            })
          )}
          {(isChatLoading || isRecording) && (
            <div css={s.messageRow(false)}>
              <div css={s.aiProfileIcon}>
                <img src={currentTutorImage} alt="tutor" />
              </div>
              <div css={s.bubble(false)}>
                {isRecording ? <span css={s.recordingPulse}>ğŸ¤ ë“£ê³  ìˆì–´ìš”...</span> : <span className="dot-flashing">...</span>}
              </div>
            </div>
          )}
        </main>
        <footer css={s.bottomArea}>
            <div css={s.bottomInner}>
                <SessionStatus />
                <div css={s.controlToolbar}>
                    <button css={s.iconBtn(isSpeakerOn)} onClick={toggleSpeaker} title={isSpeakerOn ? "TTS ë„ê¸°" : "TTS ì¼œê¸°"}>
                        {isSpeakerOn ? "ğŸ”Š" : "ğŸ”‡"}
                    </button>
                    <button 
                        css={s.iconBtn(isRecording)} 
                        onMouseDown={startRecording} onMouseUp={stopRecording}
                        onTouchStart={startRecording} onTouchEnd={stopRecording}
                    >
                        {isRecording ? "ğŸ”´" : "ğŸ¤"}
                    </button>
                    {currentMode === 'REVIEW' && (
                        <button css={s.textBtn} onClick={handleDownloadPdf} disabled={isChatLoading}>ğŸ“„ ìë£Œ ë‹¤ìš´</button>
                    )}
                </div>
                <div css={s.inputWrapper}>
                    <input 
                      type="text" 
                      placeholder={isRecording ? "ë§ì”€í•˜ì‹œëŠ” ë‚´ìš©ì„ ë“£ê³  ìˆìŠµë‹ˆë‹¤..." : "AI íŠœí„°ì—ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”."}
                      css={s.inputBox}
                      value={inputText}
                      onChange={(e) => setInputText(e.target.value)}
                      onKeyDown={handleKeyDown}
                      disabled={isChatLoading || isRecording}
                      autoFocus
                    />
                </div>
                <button css={s.sendBtn} onClick={handleSend} disabled={isChatLoading || isRecording}>ì „ì†¡</button>
            </div>
        </footer>
      </div>
    </>
  );
}

export default StudyPage;